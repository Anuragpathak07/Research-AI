{
  "papers": [
    {
      "paper_id": "http://arxiv.org/abs/2310.08437v2",
      "title": "Cold Start Latency in Serverless Computing: A Systematic Review, Taxonomy, and Future Directions",
      "abstract": "Recently, academics and the corporate sector have paid attention to serverless computing, which enables dynamic scalability and an economic model. In serverless computing, users only pay for the time they actually use resources, enabling zero scaling to optimise cost and resource utilisation. However, this approach also introduces the serverless cold start problem. Researchers have developed various solutions to address the cold start problem, yet it remains an unresolved research area. In this article, we propose a systematic literature review on clod start latency in serverless computing. Furthermore, we create a detailed taxonomy of approaches to cold start latency, which we use to investigate existing techniques for reducing the cold start time and frequency. We have classified the current studies on cold start latency into several categories such as caching and application-level optimisation-based solutions, as well as Artificial Intelligence (AI)/Machine Learning (ML)-based solutions. Moreover, we have analyzed the impact of cold start latency on quality of service, explored current cold start latency mitigation methods, datasets, and implementation platforms, and classified them into categories based on their common characteristics and features. Finally, we outline the open challenges and highlight the possible future directions.",
      "authors": [
        "Muhammed Golec",
        "Guneet Kaur Walia",
        "Mohit Kumar",
        "Felix Cuadrado",
        "Sukhpal Singh Gill",
        "Steve Uhlig"
      ],
      "year": 2023,
      "venue": "arXiv",
      "url": "https://arxiv.org/abs/2310.08437v2"
    },
    {
      "paper_id": "http://arxiv.org/abs/2211.02350v1",
      "title": "Tierkreis: A Dataflow Framework for Hybrid Quantum-Classical Computing",
      "abstract": "We present Tierkreis, a higher-order dataflow graph program representation and runtime designed for compositional, quantum-classical hybrid algorithms. The design of the system is motivated by the remote nature of quantum computers, the need for hybrid algorithms to involve cloud and distributed computing, and the long-running nature of these algorithms. The graph-based representation reflects how designers reason about and visualise algorithms, and allows automatic parallelism and asynchronicity. A strong, static type system and higher-order semantics allow for high expressivity and compositionality in the program. The flexible runtime protocol enables third-party developers to add functionality using any language or environment. With Tierkreis, quantum software developers can easily build, visualise, verify, test, and debug complex hybrid workflows, and immediately deploy them to the cloud or a custom distributed environment.",
      "authors": [
        "Seyon Sivarajah",
        "Lukas Heidemann",
        "Alan Lawrence",
        "Ross Duncan"
      ],
      "year": 2022,
      "venue": "arXiv",
      "url": "https://arxiv.org/abs/2211.02350v1"
    },
    {
      "paper_id": "http://arxiv.org/abs/2403.02240v5",
      "title": "Quantum Computing: Vision and Challenges",
      "abstract": "The recent development of quantum computing, which uses entanglement, superposition, and other quantum fundamental concepts, can provide substantial processing advantages over traditional computing. These quantum features help solve many complex problems that cannot be solved otherwise with conventional computing methods. These problems include modeling quantum mechanics, logistics, chemical-based advances, drug design, statistical science, sustainable energy, banking, reliable communication, and quantum chemical engineering. The last few years have witnessed remarkable progress in quantum software and algorithm creation and quantum hardware research, which has significantly advanced the prospect of realizing quantum computers. It would be helpful to have comprehensive literature research on this area to grasp the current status and find outstanding problems that require considerable attention from the research community working in the quantum computing industry. To better understand quantum computing, this paper examines the foundations and vision based on current research in this area. We discuss cutting-edge developments in quantum computer hardware advancement and subsequent advances in quantum cryptography, quantum software, and high-scalability quantum computers. Many potential challenges and exciting new trends for quantum technology research and development are highlighted in this paper for a broader debate.",
      "authors": [
        "Sukhpal Singh Gill",
        "Oktay Cetinkaya",
        "Stefano Marrone",
        "Daniel Claudino",
        "David Haunschild",
        "Leon Schlote",
        "Huaming Wu",
        "Carlo Ottaviani",
        "Xiaoyuan Liu",
        "Sree Pragna Machupalli",
        "Kamalpreet Kaur",
        "Priyansh Arora",
        "Ji Liu",
        "Ahmed Farouk",
        "Houbing Herbert Song",
        "Steve Uhlig",
        "Kotagiri Ramamohanarao"
      ],
      "year": 2024,
      "venue": "arXiv",
      "url": "https://arxiv.org/abs/2403.02240v5"
    },
    {
      "paper_id": "http://arxiv.org/abs/2504.10053v2",
      "title": "Synthetic Biology meets Neuromorphic Computing: Towards a bio-inspired Olfactory Perception System",
      "abstract": "In this study, we explore how the combination of synthetic biology, neuroscience modeling, and neuromorphic electronic systems offers a new approach to creating an artificial system that mimics the natural sense of smell. We argue that a co-design approach offers significant advantages in replicating the complex dynamics of odor sensing and processing. We propose a hybrid system of synthetic sensory neurons that provides three key features: (a) receptor-gated ion channels, (b) interface between synthetic biology and semiconductors and (c) event-based encoding and computing based on spiking networks. Our approach is validated using simulation-based modeling of the complete sensing and processing pipeline. This research seeks to develop a platform for ultra-sensitive, specific, and energy-efficient odor detection, with potential implications for environmental monitoring, medical diagnostics, and security.",
      "authors": [
        "Kevin Max",
        "Larissa Sames",
        "Shimeng Ye",
        "Jan Steink\u00fchler",
        "Federico Corradi"
      ],
      "year": 2025,
      "venue": "arXiv",
      "url": "https://arxiv.org/abs/2504.10053v2"
    },
    {
      "paper_id": "http://arxiv.org/abs/2505.19880v2",
      "title": "Universal Workers: A Vision for Eliminating Cold Starts in Serverless Computing",
      "abstract": "Serverless computing enables developers to deploy code without managing infrastructure, but suffers from cold start overhead when initializing new function instances. Existing solutions such as \"keep-alive\" or \"pre-warming\" are costly and unreliable under bursty workloads. We propose universal workers, which are computational units capable of executing any function with minimal initialization overhead. Based on an analysis of production workload traces, our key insight is that requests in Function-as-a-Service (FaaS) platforms show a highly skewed distribution, with most requests invoking a small subset of functions. We exploit this observation to approximate universal workers through locality groups and three-tier caching (handler, install, import). With this work, we aim to enable more efficient and scalable FaaS platforms capable of handling diverse workloads with minimal initialization overhead.",
      "authors": [
        "Saman Akbari",
        "Manfred Hauswirth"
      ],
      "year": 2025,
      "venue": "arXiv",
      "url": "https://arxiv.org/abs/2505.19880v2"
    },
    {
      "paper_id": "http://arxiv.org/abs/2207.05399v2",
      "title": "Placement of Microservices-based IoT Applications in Fog Computing: A Taxonomy and Future Directions",
      "abstract": "The Fog computing paradigm utilises distributed, heterogeneous and resource-constrained devices at the edge of the network for efficient deployment of latency-critical and bandwidth-hungry IoT application services. Moreover, MicroService Architecture (MSA) is increasingly adopted to keep up with the rapid development and deployment needs of fast-evolving IoT applications. Due to the fine-grained modularity of the microservices and their independently deployable and scalable nature, MSA exhibits great potential in harnessing Fog and Cloud resources, thus giving rise to novel paradigms like Osmotic computing. The loosely coupled nature of the microservices, aided by the container orchestrators and service mesh technologies, enables the dynamic composition of distributed and scalable microservices to achieve diverse performance requirements of the IoT applications using distributed Fog resources. To this end, efficient placement of microservice plays a vital role, and scalable placement algorithms are required to utilise the said characteristics of the MSA while overcoming novel challenges introduced by the architecture. Thus, we present a comprehensive taxonomy of recent literature on microservices-based IoT applications placement within Fog computing environments. Furthermore, we organise multiple taxonomies to capture the main aspects of the placement problem, analyse and classify related works, identify research gaps within each category, and discuss future research directions.",
      "authors": [
        "Samodha Pallewatta",
        "Vassilis Kostakos",
        "Rajkumar Buyya"
      ],
      "year": 2022,
      "venue": "arXiv",
      "url": "https://arxiv.org/abs/2207.05399v2"
    },
    {
      "paper_id": "http://arxiv.org/abs/2209.09367v4",
      "title": "Supporting Multi-Cloud in Serverless Computing",
      "abstract": "Serverless computing is a widely adopted cloud execution model composed of Function-as-a-Service (FaaS) and Backend-as-a-Service (BaaS) offerings. The increased level of abstraction makes vendor lock-in inherent to serverless computing, raising more concerns than previous cloud paradigms. Multi-cloud serverless is a promising emerging approach against vendor lock-in, yet multiple challenges must be overcome to tap its potential. First, we need to be aware of both the performance and cost of each FaaS provider. Second, a multi-cloud architecture must be proposed before deploying a multi-cloud workflow. Domain-specific serverless offerings must then be integrated into the multi-cloud architecture to improve performance or save costs. Moreover, dealing with serverless offerings from multiple providers is challenging. Finally, we require workload portability support for serverless multi-cloud.   In this paper, we present a multi-cloud library for cross-serverless offerings. We develop the End Analysis System (EAS) to support comparison among public FaaS providers in terms of performance and cost. Moreover, we design proof-of-concept multi-cloud architectures with domain-specific serverless offerings to alleviate problems such as data gravity. Finally, we deploy workloads on these architectures to evaluate several public FaaS offerings.",
      "authors": [
        "Haidong Zhao",
        "Zakaria Benomar",
        "Tobias Pfandzelter",
        "Nikolaos Georgantas"
      ],
      "year": 2022,
      "venue": "arXiv",
      "url": "https://arxiv.org/abs/2209.09367v4"
    },
    {
      "paper_id": "http://arxiv.org/abs/2109.12195v1",
      "title": "A Manifesto for Modern Fog and Edge Computing: Vision, New Paradigms, Opportunities, and Future Directions",
      "abstract": "The advancements in the use of Internet of Things (IoT) devices is increasing continuously and generating huge amounts of data in a fast manner. Cloud computing is an important paradigm which processes and manages user data effectively. Further, fog and edge computing paradigms are introduced to improve user service by reducing latency and response time. This chapter presents a manifesto for modern fog and edge computing systems based on the current research trends. Further, architectures and applications of fog and edge computing are explained. Moreover, research opportunities and promising future directions are presented with respect to the new paradigms, which will be helpful for practitioners, researchers, and academicians to continue their research.",
      "authors": [
        "Sukhpal Singh Gill"
      ],
      "year": 2021,
      "venue": "arXiv",
      "url": "https://arxiv.org/abs/2109.12195v1"
    },
    {
      "paper_id": "http://arxiv.org/abs/2104.11385v1",
      "title": "In-Situ Assessment of Device-Side Compute Work for Dynamic Load Balancing in a GPU-Accelerated PIC Code",
      "abstract": "Maintaining computational load balance is important to the performant behavior of codes which operate under a distributed computing model. This is especially true for GPU architectures, which can suffer from memory oversubscription if improperly load balanced. We present enhancements to traditional load balancing approaches and explicitly target GPU architectures, exploring the resulting performance. A key component of our enhancements is the introduction of several GPU-amenable strategies for assessing compute work. These strategies are implemented and benchmarked to find the most optimal data collection methodology for in-situ assessment of GPU compute work. For the fully kinetic particle-in-cell code WarpX, which supports MPI+CUDA parallelism, we investigate the performance of the improved dynamic load balancing via a strong scaling-based performance model and show that, for a laser-ion acceleration test problem run with up to 6144 GPUs on Summit, the enhanced dynamic load balancing achieves from 62%--74% (88% when running on 6 GPUs) of the theoretically predicted maximum speedup; for the 96-GPU case, we find that dynamic load balancing improves performance relative to baselines without load balancing (3.8x speedup) and with static load balancing (1.2x speedup). Our results provide important insights into dynamic load balancing and performance assessment, and are particularly relevant in the context of distributed memory applications ran on GPUs.",
      "authors": [
        "Michael E. Rowan",
        "Axel Huebl",
        "Kevin N. Gott",
        "Jack Deslippe",
        "Maxence Th\u00e9venet",
        "Remi Lehe",
        "Jean-Luc Vay"
      ],
      "year": 2021,
      "venue": "arXiv",
      "url": "https://arxiv.org/abs/2104.11385v1"
    },
    {
      "paper_id": "http://arxiv.org/abs/2010.08774v1",
      "title": "The role of interactive super-computing in using HPC for urgent decision making",
      "abstract": "Technological advances are creating exciting new opportunities that have the potential to move HPC well beyond traditional computational workloads. In this paper we focus on the potential for HPC to be instrumental in responding to disasters such as wildfires, hurricanes, extreme flooding, earthquakes, tsunamis, winter weather conditions, and accidents. Driven by the VESTEC EU funded H2020 project, our research looks to prove HPC as a tool not only capable of simulating disasters once they have happened, but also one which is able to operate in a responsive mode, supporting disaster response teams making urgent decisions in real-time. Whilst this has the potential to revolutionise disaster response, it requires the ability to drive HPC interactively, both from the user's perspective and also based upon the arrival of data. As such interactivity is a critical component in enabling HPC to be exploited in the role of supporting disaster response teams so that urgent decision makers can make the correct decision first time, every time.",
      "authors": [
        "Nick Brown",
        "Rupert Nash",
        "Gordon Gibb",
        "Bianca Prodan",
        "Max Kontak",
        "Vyacheslav Olshevsky",
        "Wei Der Chien"
      ],
      "year": 2020,
      "venue": "arXiv",
      "url": "https://arxiv.org/abs/2010.08774v1"
    },
    {
      "paper_id": "http://arxiv.org/abs/2504.03671v1",
      "title": "HiAER-Spike: Hardware-Software Co-Design for Large-Scale Reconfigurable Event-Driven Neuromorphic Computing",
      "abstract": "In this work, we present HiAER-Spike, a modular, reconfigurable, event-driven neuromorphic computing platform designed to execute large spiking neural networks with up to 160 million neurons and 40 billion synapses - roughly twice the neurons of a mouse brain at faster-than real-time. This system, which is currently under construction at the UC San Diego Supercomputing Center, comprises a co-designed hard- and software stack that is optimized for run-time massively parallel processing and hierarchical address-event routing (HiAER) of spikes while promoting memory-efficient network storage and execution. Our architecture efficiently handles both sparse connectivity and sparse activity for robust and low-latency event-driven inference for both edge and cloud computing. A Python programming interface to HiAER-Spike, agnostic to hardware-level detail, shields the user from complexity in the configuration and execution of general spiking neural networks with virtually no constraints in topology. The system is made easily available over a web portal for use by the wider community. In the following we provide an overview of the hard- and software stack, explain the underlying design principles, demonstrate some of the system's capabilities and solicit feedback from the broader neuromorphic community.",
      "authors": [
        "Gwenevere Frank",
        "Gopabandhu Hota",
        "Keli Wang",
        "Abhinav Uppal",
        "Omowuyi Olajide",
        "Kenneth Yoshimoto",
        "Leif Gibb",
        "Qingbo Wang",
        "Johannes Leugering",
        "Stephen Deiss",
        "Gert Cauwenberghs"
      ],
      "year": 2025,
      "venue": "arXiv",
      "url": "https://arxiv.org/abs/2504.03671v1"
    },
    {
      "paper_id": "http://arxiv.org/abs/2011.12148v1",
      "title": "Fast error-safe MOID computation involving hyperbolic orbits",
      "abstract": "We extend our previous algorithm computing the minimum orbital intersection distance (MOID) to include hyperbolic orbits, and mixed combinations ellipse--hyperbola. The MOID is computed by finding all stationary points of the distance function, equivalent to finding all the roots of an algebraic polynomial equation of 16th degree. The updated algorithm carries about numerical errors as well, and benchmarks confirmed its numeric reliability together with high computing performance.",
      "authors": [
        "Roman. V. Baluev"
      ],
      "year": 2020,
      "venue": "arXiv",
      "url": "https://arxiv.org/abs/2011.12148v1"
    },
    {
      "paper_id": "http://arxiv.org/abs/2307.11124v2",
      "title": "Approximate Computing Survey, Part I: Terminology and Software & Hardware Approximation Techniques",
      "abstract": "The rapid growth of demanding applications in domains applying multimedia processing and machine learning has marked a new era for edge and cloud computing. These applications involve massive data and compute-intensive tasks, and thus, typical computing paradigms in embedded systems and data centers are stressed to meet the worldwide demand for high performance. Concurrently, over the last 15 years, the semiconductor industry has established power efficiency as a first-class design concern. As a result, the community of computing systems is forced to find alternative design approaches to facilitate high-performance and power-efficient computing. Among the examined solutions, Approximate Computing has attracted an ever-increasing interest, which has resulted in novel approximation techniques for all the layers of the traditional computing stack. More specifically, during the last decade, a plethora of approximation techniques in software (programs, frameworks, compilers, runtimes, languages), hardware (circuits, accelerators), and architectures (processors, memories) have been proposed in the literature. The current article is Part I of a comprehensive survey on Approximate Computing. It reviews its motivation, terminology and principles, as well it classifies the state-of-the-art software & hardware approximation techniques, presents their technical details, and reports a comparative quantitative analysis.",
      "authors": [
        "Vasileios Leon",
        "Muhammad Abdullah Hanif",
        "Giorgos Armeniakos",
        "Xun Jiao",
        "Muhammad Shafique",
        "Kiamal Pekmestzi",
        "Dimitrios Soudris"
      ],
      "year": 2023,
      "venue": "arXiv",
      "url": "https://arxiv.org/abs/2307.11124v2"
    },
    {
      "paper_id": "http://arxiv.org/abs/2212.02378v1",
      "title": "Confidential High-Performance Computing in the Public Cloud",
      "abstract": "High-Performance Computing (HPC) in the public cloud democratizes the supercomputing power that most users cannot afford to purchase and maintain. Researchers have studied its viability, performance, and usability. However, HPC in the cloud has a unique feature -- users have to export data and computation to somewhat untrusted cloud platforms. Users will either fully trust cloud providers to protect from all kinds of attacks or keep sensitive assets in-house instead. With the recent deployment of the Trusted Execution Environment (TEE) in the cloud, confidential computing for HPC in the cloud is becoming practical for addressing users' privacy concerns. This paper discusses the threat models, unique challenges, possible solutions, and significant gaps, focusing on TEE-based confidential HPC computing. We hope this discussion will improve the understanding of this new topic for HPC in the cloud and promote new research directions.",
      "authors": [
        "Keke Chen"
      ],
      "year": 2022,
      "venue": "arXiv",
      "url": "https://arxiv.org/abs/2212.02378v1"
    },
    {
      "paper_id": "http://arxiv.org/abs/1811.06373v2",
      "title": "Fast error-controlling MOID computation for confocal elliptic orbits",
      "abstract": "We present an algorithm to compute the minimum orbital intersection distance (MOID), or global minimum of the distance between the points lying on two Keplerian ellipses. This is achieved by finding all stationary points of the distance function, based on solving an algebraic polynomial equation of $16$th degree. The algorithm tracks numerical errors appearing on the way, and treats carefully nearly degenerate cases, including practical cases with almost circular and almost coplanar orbits. Benchmarks confirm its high numeric reliability and accuracy, and that regardless of its error--controlling overheads, this algorithm pretends to be one of the fastest MOID computation methods available to date, so it may be useful in processing large catalogs.",
      "authors": [
        "Roman V. Baluev",
        "Denis V. Mikryukov"
      ],
      "year": 2018,
      "venue": "arXiv",
      "url": "https://arxiv.org/abs/1811.06373v2"
    },
    {
      "paper_id": "http://arxiv.org/abs/1801.05610v3",
      "title": "A Taxonomy for Management and Optimization of Multiple Resources in Edge Computing",
      "abstract": "Edge computing is promoted to meet increasing performance needs of data-driven services using computational and storage resources close to the end devices, at the edge of the current network. To achieve higher performance in this new paradigm one has to consider how to combine the efficiency of resource usage at all three layers of architecture: end devices, edge devices, and the cloud. While cloud capacity is elastically extendable, end devices and edge devices are to various degrees resource-constrained. Hence, an efficient resource management is essential to make edge computing a reality. In this work, we first present terminology and architectures to characterize current works within the field of edge computing. Then, we review a wide range of recent articles and categorize relevant aspects in terms of 4 perspectives: resource type, resource management objective, resource location, and resource use. This taxonomy and the ensuing analysis is used to identify some gaps in the existing research. Among several research gaps, we found that research is less prevalent on data, storage, and energy as a resource, and less extensive towards the estimation, discovery and sharing objectives. As for resource types, the most well-studied resources are computation and communication resources. Our analysis shows that resource management at the edge requires a deeper understanding of how methods applied at different levels and geared towards different resource types interact. Specifically, the impact of mobility and collaboration schemes requiring incentives are expected to be different in edge architectures compared to the classic cloud solutions. Finally, we find that fewer works are dedicated to the study of non-functional properties or to quantifying the footprint of resource management techniques, including edge-specific means of migrating data and services.",
      "authors": [
        "Klervie Tocz\u00e9",
        "Simin Nadjm-Tehrani"
      ],
      "year": 2018,
      "venue": "arXiv",
      "url": "https://arxiv.org/abs/1801.05610v3"
    },
    {
      "paper_id": "http://arxiv.org/abs/2311.14679v2",
      "title": "\"Medium-n studies\" in computing education conferences",
      "abstract": "Good (Frequentist) statistical practice requires that statistical tests be performed in order to determine if the phenomenon being observed could plausibly occur by chance if the null hypothesis is false. Good practice also requires that a test is not performed if the study is underpowered: if the number of observations is not sufficiently large to be able to reliably detect the effect one hypothesizes, even if the effect exists. Running underpowered studies runs the risk of false negative results. This creates tension in the guidelines and expectations for computer science education conferences: while things are clear for studies with a large number of observations, researchers should in fact not compute p-values and perform statistical tests if the number of observations is too small. The issue is particularly live in CSed venues, since class sizes where those issues are salient are common. We outline the considerations for when to compute and when not to compute p-values in different settings encountered by computer science education researchers. We survey the author and reviewer guidelines in different computer science education conferences (ICER, SIGCSE TS, ITiCSE, EAAI, CompEd, Koli Calling). We present summary data and make several preliminary observations about reviewer guidelines: guidelines vary from conference to conference; guidelines allow for qualitative studies, and, in some cases, experience reports, but guidelines do not generally explicitly indicate that a paper should have at least one of (1) an appropriately-powered statistical analysis or (2) rich qualitative descriptions. We present preliminary ideas for addressing the tension in the guidelines between small-n and large-n studies",
      "authors": [
        "Michael Guerzhoy"
      ],
      "year": 2023,
      "venue": "arXiv",
      "url": "https://arxiv.org/abs/2311.14679v2"
    },
    {
      "paper_id": "http://arxiv.org/abs/2107.01984v1",
      "title": "A Systematic Literature Review of Empiricism and Norms of Reporting in Computing Education Research Literature",
      "abstract": "Computing Education Research (CER) is critical for supporting the increasing number of students who need to learn computing skills. To systematically advance knowledge, publications must be clear enough to support replications, meta-analyses, and theory-building. The goal of this study is to characterize the reporting of empiricism in CER literature by identifying whether publications include information to support replications, meta-analyses, and theory building. The research questions are: RQ1) What percentage of papers in CER venues have empirical evaluation? RQ2) What are the characteristics of the empirical evaluation? RQ3) Do the papers with empirical evaluation follow reporting norms (both for inclusion and for labeling of key information)? We conducted an SLR of 427 papers published during 2014 and 2015 in five CER venues: SIGCSE TS, ICER, ITiCSE, TOCE, and CSE. We developed and applied the CER Empiricism Assessment Rubric. Over 80% of papers had some form of empirical evaluation. Quantitative evaluation methods were the most frequent. Papers most frequently reported results on interventions around pedagogical techniques, curriculum, community, or tools. There was a split in papers that had some type of comparison between an intervention and some other data set or baseline. Many papers lacked properly reported research objectives, goals, research questions, or hypotheses, description of participants, study design, data collection, and threats to validity. CER authors are contributing empirical results to the literature; however, not all norms for reporting are met. We encourage authors to provide clear, labeled details about their work so readers can use the methodologies and results for replications and meta-analyses. As our community grows, our reporting of CER should mature to help establish computing education theory to support the next generation of computing learners.",
      "authors": [
        "Sarah Heckman",
        "Jeffrey C. Carver",
        "Mark Sherriff",
        "Ahmed Al-Zubidy"
      ],
      "year": 2021,
      "venue": "arXiv",
      "url": "https://arxiv.org/abs/2107.01984v1"
    },
    {
      "paper_id": "http://arxiv.org/abs/2307.11128v2",
      "title": "Approximate Computing Survey, Part II: Application-Specific & Architectural Approximation Techniques and Applications",
      "abstract": "The challenging deployment of compute-intensive applications from domains such as Artificial Intelligence (AI) and Digital Signal Processing (DSP), forces the community of computing systems to explore new design approaches. Approximate Computing appears as an emerging solution, allowing to tune the quality of results in the design of a system in order to improve the energy efficiency and/or performance. This radical paradigm shift has attracted interest from both academia and industry, resulting in significant research on approximation techniques and methodologies at different design layers (from system down to integrated circuits). Motivated by the wide appeal of Approximate Computing over the last 10 years, we conduct a two-part survey to cover key aspects (e.g., terminology and applications) and review the state-of-the art approximation techniques from all layers of the traditional computing stack. Part II of the survey classifies and presents the technical details of application-specific and architectural approximation techniques, which both target the design of resource-efficient processors/accelerators and systems. Moreover, it reports a quantitative analysis of the techniques and a detailed analysis of the application spectrum of Approximate Computing, and finally, it discusses open challenges and future directions.",
      "authors": [
        "Vasileios Leon",
        "Muhammad Abdullah Hanif",
        "Giorgos Armeniakos",
        "Xun Jiao",
        "Muhammad Shafique",
        "Kiamal Pekmestzi",
        "Dimitrios Soudris"
      ],
      "year": 2023,
      "venue": "arXiv",
      "url": "https://arxiv.org/abs/2307.11128v2"
    },
    {
      "paper_id": "http://arxiv.org/abs/2011.10569v1",
      "title": "Vector computation",
      "abstract": "Quantum physical resources are directional quantities that can be formalized by unit vectors or the associated orthogonal projection operators. When compared to classical computational states which are elements of (power) sets vector computations offer (dis)advantages.",
      "authors": [
        "Karl Svozil"
      ],
      "year": 2020,
      "venue": "arXiv",
      "url": "https://arxiv.org/abs/2011.10569v1"
    },
    {
      "paper_id": "http://arxiv.org/abs/1810.06046v1",
      "title": "Accelerator Virtualization in Fog Computing: Moving From the Cloud to the Edge",
      "abstract": "Hardware accelerators are available on the Cloud for enhanced analytics. Next generation Clouds aim to bring enhanced analytics using accelerators closer to user devices at the edge of the network for improving Quality-of-Service by minimizing end-to-end latencies and response times. The collective computing model that utilizes resources at the Cloud-Edge continuum in a multi-tier hierarchy comprising the Cloud, the Edge and user devices is referred to as Fog computing. This article identifies challenges and opportunities in making accelerators accessible at the Edge. A holistic view of the Fog architecture is key to pursuing meaningful research in this area.",
      "authors": [
        "Blesson Varghese",
        "Carlos Reano",
        "Federico Silla"
      ],
      "year": 2018,
      "venue": "arXiv",
      "url": "https://arxiv.org/abs/1810.06046v1"
    },
    {
      "paper_id": "http://arxiv.org/abs/2503.08854v2",
      "title": "Survey-Wide Asteroid Discovery with a High-Performance Computing Enabled Non-Linear Digital Tracking Framework",
      "abstract": "Modern astronomical surveys detect asteroids by linking together their appearances across multiple images taken over time. This approach faces limitations in detecting faint asteroids and handling the computational complexity of trajectory linking. We present a novel method that adapts ``digital tracking\" - traditionally used for short-term linear asteroid motion across images - to work with large-scale synoptic surveys such as the Vera Rubin Observatory Legacy Survey of Space and Time (Rubin/LSST). Our approach combines hundreds of sparse observations of individual asteroids across their non-linear orbital paths to enhance detection sensitivity by several magnitudes. To address the computational challenges of processing massive data sets and dense orbital phase spaces, we developed a specialized high-performance computing architecture. We demonstrate the effectiveness of our method through experiments that take advantage of the extensive computational resources at Lawrence Livermore National Laboratory. This work enables the detection of significantly fainter asteroids in existing and future survey data, potentially increasing the observable asteroid population by orders of magnitude across different orbital families, from near-Earth objects (NEOs) to Kuiper belt objects (KBOs).",
      "authors": [
        "Nathan Golovich",
        "Trevor Steil",
        "Alex Geringer-Sameth",
        "Keita Iwabuchi",
        "Ryan Dozier",
        "Roger Pearce"
      ],
      "year": 2025,
      "venue": "arXiv",
      "url": "https://arxiv.org/abs/2503.08854v2"
    },
    {
      "paper_id": "http://arxiv.org/abs/2511.01861v1",
      "title": "Conceptual Design Report for FAIR Computing",
      "abstract": "This Conceptual Design Report (CDR) presents the plans of the computing infrastructure for research at FAIR, Darmstadt, Germany. It presents the computing requirements of the various research groups, the policies for the computing and storage infrastructure, the foreseen FAIR computing model including the open data, software and services policies and architecture for the periods starting in 2028 with the \"first science (plus)\" phase to the modularized start version of FAIR. The overall ambition is to create a federated and centrally-orchestrated infrastructure serving the large diversity of the research lines present with sufficient scalability and flexibility to cope with future data challenges that will be present at FAIR.",
      "authors": [
        "Johan Messchendorp",
        "Mohammad Al-Turany",
        "Volker Friese",
        "Thorsten Kollegger",
        "Bastian Loeher",
        "Jochen Markert",
        "Andrew Mistry",
        "Thomas Neff",
        "Adrian Oeftiger",
        "Michael Papenbrock",
        "Stephane Pietri",
        "Shahab Sanjari",
        "Tobias Stockmanns"
      ],
      "year": 2025,
      "venue": "arXiv",
      "url": "https://arxiv.org/abs/2511.01861v1"
    },
    {
      "paper_id": "http://arxiv.org/abs/1801.04179v1",
      "title": "Arhuaco: Deep Learning and Isolation Based Security for Distributed High-Throughput Computing",
      "abstract": "Grid computing systems require innovative methods and tools to identify cybersecurity incidents and perform autonomous actions i.e. without administrator intervention. They also require methods to isolate and trace job payload activity in order to protect users and find evidence of malicious behavior. We introduce an integrated approach of security monitoring via Security by Isolation with Linux Containers and Deep Learning methods for the analysis of real time data in Grid jobs running inside virtualized High-Throughput Computing infrastructure in order to detect and prevent intrusions. A dataset for malware detection in Grid computing is described. We show in addition the utilization of generative methods with Recurrent Neural Networks to improve the collected dataset. We present Arhuaco, a prototype implementation of the proposed methods. We empirically study the performance of our technique. The results show that Arhuaco outperforms other methods used in Intrusion Detection Systems for Grid Computing. The study is carried out in the ALICE Collaboration Grid, part of the Worldwide LHC Computing Grid.",
      "authors": [
        "A. Gomez Ramirez",
        "C. Lara",
        "L. Betev",
        "D. Bilanovic",
        "U. Kebschull"
      ],
      "year": 2018,
      "venue": "arXiv",
      "url": "https://arxiv.org/abs/1801.04179v1"
    },
    {
      "paper_id": "http://arxiv.org/abs/2204.12580v1",
      "title": "Scheduling IoT Applications in Edge and Fog Computing Environments: A Taxonomy and Future Directions",
      "abstract": "Fog computing, as a distributed paradigm, offers cloud-like services at the edge of the network with low latency and high-access bandwidth to support a diverse range of IoT application scenarios. To fully utilize the potential of this computing paradigm, scalable, adaptive, and accurate scheduling mechanisms and algorithms are required to efficiently capture the dynamics and requirements of users, IoT applications, environmental properties, and optimization targets. This paper presents a taxonomy of recent literature on scheduling IoT applications in Fog computing. Based on our new classification schemes, current works in the literature are analyzed, research gaps of each category are identified, and respective future directions are described.",
      "authors": [
        "Mohammad Goudarzi",
        "Marimuthu Palaniswami",
        "Rajkumar Buyya"
      ],
      "year": 2022,
      "venue": "arXiv",
      "url": "https://arxiv.org/abs/2204.12580v1"
    },
    {
      "paper_id": "http://arxiv.org/abs/1711.03660v1",
      "title": "TARCO: Two-Stage Auction for D2D Relay Aided Computation Resource Allocation in Hetnet",
      "abstract": "In heterogeneous cellular network, task scheduling for computation offloading is one of the biggest challenges. Most works focus on alleviating heavy burden of macro base stations by moving the computation tasks on macro-cell user equipment (MUE) to remote cloud or small-cell base stations. But the selfishness of network users is seldom considered. Motivated by the cloud edge computing, this paper provides incentive for task transfer from macro cell users to small cell base stations. The proposed incentive scheme utilizes small cell user equipment to provide relay service. The problem of computation offloading is modelled as a two-stage auction, in which the remote MUEs with common social character can form a group and then buy the computation resource of small-cell base stations with the relay of small cell user equipment. A two-stage auction scheme named TARCO is contributed to maximize utilities for both sellers and buyers in the network. The truthful, individual rationality and budget balance of the TARCO are also proved in this paper. In addition, two algorithms are proposed to further refine TARCO on the social welfare of the network. Extensive simulation results demonstrate that, TARCO is better than random algorithm by about 104.90% in terms of average utility of MUEs, while the performance of TARCO is further improved up to 28.75% and 17.06% by the proposed two algorithms, respectively.",
      "authors": [
        "Long Chen",
        "Jigang Wu",
        "Xinxiang Zhang"
      ],
      "year": 2017,
      "venue": "arXiv",
      "url": "https://arxiv.org/abs/1711.03660v1"
    },
    {
      "paper_id": "http://arxiv.org/abs/1705.08449v4",
      "title": "Developing an edge computing platform for real-time descriptive analytics",
      "abstract": "The Internet of Mobile Things encompasses stream data being generated by sensors, network communications that pull and push these data streams, as well as running processing and analytics that can effectively leverage actionable information for transportation planning, management, and business advantage. Edge computing emerges as a new paradigm that decentralizes the communication, computation, control and storage resources from the cloud to the edge of the network. This paper proposes an edge computing platform where mobile edge nodes are physical devices deployed on a transit bus where descriptive analytics is used to uncover meaningful patterns from real-time transit data streams. An application experiment is used to evaluate the advantages and disadvantages of our proposed platform to support descriptive analytics at a mobile edge node and generate actionable information to transit managers.",
      "authors": [
        "Hung Cao",
        "Monica Wachowicz",
        "Sangwhan Cha"
      ],
      "year": 2017,
      "venue": "arXiv",
      "url": "https://arxiv.org/abs/1705.08449v4"
    },
    {
      "paper_id": "http://arxiv.org/abs/1808.02838v1",
      "title": "On the Effect of Task-to-Worker Assignment in Distributed Computing Systems with Stragglers",
      "abstract": "We study the expected completion time of some recently proposed algorithms for distributed computing which redundantly assign computing tasks to multiple machines in order to tolerate a certain number of machine failures. We analytically show that not only the amount of redundancy but also the task-to-machine assignments affect the latency in a distributed system. We study systems with a fixed number of computing tasks that are split in possibly overlapping batches, and independent exponentially distributed machine service times. We show that, for such systems, the uniform replication of non- overlapping (disjoint) batches of computing tasks achieves the minimum expected computing time.",
      "authors": [
        "Amir Behrouzi-Far",
        "Emina Soljanin"
      ],
      "year": 2018,
      "venue": "arXiv",
      "url": "https://arxiv.org/abs/1808.02838v1"
    },
    {
      "paper_id": "http://arxiv.org/abs/2103.04505v4",
      "title": "Split Computing and Early Exiting for Deep Learning Applications: Survey and Research Challenges",
      "abstract": "Mobile devices such as smartphones and autonomous vehicles increasingly rely on deep neural networks (DNNs) to execute complex inference tasks such as image classification and speech recognition, among others. However, continuously executing the entire DNN on mobile devices can quickly deplete their battery. Although task offloading to cloud/edge servers may decrease the mobile device's computational burden, erratic patterns in channel quality, network, and edge server load can lead to a significant delay in task execution. Recently, approaches based on split computing (SC) have been proposed, where the DNN is split into a head and a tail model, executed respectively on the mobile device and on the edge server. Ultimately, this may reduce bandwidth usage as well as energy consumption. Another approach, called early exiting (EE), trains models to embed multiple \"exits\" earlier in the architecture, each providing increasingly higher target accuracy. Therefore, the trade-off between accuracy and delay can be tuned according to the current conditions or application demands. In this paper, we provide a comprehensive survey of the state of the art in SC and EE strategies by presenting a comparison of the most relevant approaches. We conclude the paper by providing a set of compelling research challenges.",
      "authors": [
        "Yoshitomo Matsubara",
        "Marco Levorato",
        "Francesco Restuccia"
      ],
      "year": 2021,
      "venue": "arXiv",
      "url": "https://arxiv.org/abs/2103.04505v4"
    },
    {
      "paper_id": "http://arxiv.org/abs/1702.06082v1",
      "title": "Coding for Distributed Fog Computing",
      "abstract": "Redundancy is abundant in Fog networks (i.e., many computing and storage points) and grows linearly with network size. We demonstrate the transformational role of coding in Fog computing for leveraging such redundancy to substantially reduce the bandwidth consumption and latency of computing. In particular, we discuss two recently proposed coding concepts, namely Minimum Bandwidth Codes and Minimum Latency Codes, and illustrate their impacts in Fog computing. We also review a unified coding framework that includes the above two coding techniques as special cases, and enables a tradeoff between computation latency and communication load to optimize system performance. At the end, we will discuss several open problems and future research directions.",
      "authors": [
        "Songze Li",
        "Mohammad Ali Maddah-Ali",
        "A. Salman Avestimehr"
      ],
      "year": 2017,
      "venue": "arXiv",
      "url": "https://arxiv.org/abs/1702.06082v1"
    },
    {
      "paper_id": "http://arxiv.org/abs/1504.00806v1",
      "title": "Synergy of Volunteer Measurements and Volunteer Computing for Effective Data Collecting, Processing, Simulating and Analyzing on a Worldwide Scale",
      "abstract": "The paper concerns the hype idea of \"Citizen Science\" and the related paradigm shift: to go from the passive \"volunteer computing\" to other volunteer actions like \"volunteer measurements\" under guidance of scientists. They can be carried out by ordinary people with standard computing gadgets (smartphone, tablet, etc.) and the various standard sensors in them. Here the special attention is paid to the system of volunteer scientific measurements to study air showers caused by cosmic rays. The technical implementation is based on integration of data about registered night flashes (by radiometric software) in shielded camera chip, synchronized time and GPS-data in ordinary gadgets: to identify night \"air showers\" of elementary particles; to analyze the frequency and to map the distribution of \"air showers\" in the densely populated cities. The project currently includes the students of the National Technical University of Ukraine \"KPI\", which are compactly located in Kyiv city and contribute their volunteer measurements. The technology would be very effective for other applications also, especially if it will be automated (e.g., on the basis of XtremWeb or/and BOINC technologies for distributed computing) and used in some small area with many volunteers, e.g. in local communities (Corporative/Community Crowd Computing).",
      "authors": [
        "Nikita Gordienko",
        "Oleg Lodygensky",
        "Gilles Fedak",
        "Yuri Gordienko"
      ],
      "year": 2015,
      "venue": "arXiv",
      "url": "https://arxiv.org/abs/1504.00806v1"
    },
    {
      "paper_id": "http://arxiv.org/abs/2106.09922v1",
      "title": "A Fresh Approach to Evaluate Performance in Distributed Parallel Genetic Algorithms",
      "abstract": "This work proposes a novel approach to evaluate and analyze the behavior of multi-population parallel genetic algorithms (PGAs) when running on a cluster of multi-core processors. In particular, we deeply study their numerical and computational behavior by proposing a mathematical model representing the observed performance curves. In them, we discuss the emerging mathematical descriptions of PGA performance instead of, e.g., individual isolated results subject to visual inspection, for a better understanding of the effects of the number of cores used (scalability), their migration policy (the migration gap, in this paper), and the features of the solved problem (type of encoding and problem size). The conclusions based on the real figures and the numerical models fitting them represent a fresh way of understanding their speed-up, running time, and numerical effort, allowing a comparison based on a few meaningful numeric parameters. This represents a set of conclusions beyond the usual textual lessons found in past works on PGAs. It can be used as an estimation tool for the future performance of the algorithms and a way of finding out their limitations.",
      "authors": [
        "Tomohiro Harada",
        "Enrique Alba",
        "Gabriel Luque"
      ],
      "year": 2021,
      "venue": "arXiv",
      "url": "https://arxiv.org/abs/2106.09922v1"
    },
    {
      "paper_id": "http://arxiv.org/abs/1509.09180v4",
      "title": "How to Verify a Quantum Computation",
      "abstract": "We give a new theoretical solution to a leading-edge experimental challenge, namely to the verification of quantum computations in the regime of high computational complexity. Our results are given in the language of quantum interactive proof systems. Specifically, we show that any language in $\\mathsf{BQP}$ has a quantum interactive proof system with a polynomial-time classical verifier (who can also prepare random single-qubit pure states), and a quantum polynomial-time prover. Here, soundness is unconditional--i.e., it holds even for computationally unbounded provers. Compared to prior work achieving similar results, our technique does not require the encoding of the input or of the computation; instead, we rely on encryption of the input (together with a method to perform computations on encrypted inputs), and show that the random choice between three types of input (defining a computational run, versus two types of test runs) suffices. Because the overhead is very low for each run (it is linear in the size of the circuit), this shows that verification could be achieved at minimal cost compared to performing the computation. As a proof technique, we use a reduction to an entanglement-based protocol; to the best of our knowledge, this is the first time this technique has been used in the context of verification of quantum computations, and it enables a relatively straightforward analysis.",
      "authors": [
        "Anne Broadbent"
      ],
      "year": 2015,
      "venue": "arXiv",
      "url": "https://arxiv.org/abs/1509.09180v4"
    },
    {
      "paper_id": "http://arxiv.org/abs/2112.00984v1",
      "title": "Measurement Crosstalk Errors in Cloud-Based Quantum Computing",
      "abstract": "Quantum technologies available currently contain noise in general, often dubbed noisy intermediate-scale quantum (NISQ) systems. We here present the verification of noise in measurement readout errors in cloud-based quantum computing services, IBMQ and Rigetti, by directly performing quantum detector tomography, and show that there exist measurement crosstalk errors. We provide the characterization and the quantification of noise in a quantum measurement of multiple qubits. We remark that entanglement is found as a source of crosstalk errors in a measurement of three qubits.",
      "authors": [
        "Seungchan Seo",
        "Joonwoo Bae"
      ],
      "year": 2021,
      "venue": "arXiv",
      "url": "https://arxiv.org/abs/2112.00984v1"
    }
  ],
  "clusters": [
    {
      "cluster_id": "0",
      "name": "Computing Performance",
      "paper_count": 11,
      "trajectory": "Stable",
      "papers": [
        {
          "paper_id": "http://arxiv.org/abs/2504.10053v2",
          "title": "Synthetic Biology meets Neuromorphic Computing: Towards a bio-inspired Olfactory Perception System",
          "abstract": "In this study, we explore how the combination of synthetic biology, neuroscience modeling, and neuromorphic electronic systems offers a new approach to creating an artificial system that mimics the natural sense of smell. We argue that a co-design approach offers significant advantages in replicating the complex dynamics of odor sensing and processing. We propose a hybrid system of synthetic sensory neurons that provides three key features: (a) receptor-gated ion channels, (b) interface between synthetic biology and semiconductors and (c) event-based encoding and computing based on spiking networks. Our approach is validated using simulation-based modeling of the complete sensing and processing pipeline. This research seeks to develop a platform for ultra-sensitive, specific, and energy-efficient odor detection, with potential implications for environmental monitoring, medical diagnostics, and security.",
          "authors": [
            "Kevin Max",
            "Larissa Sames",
            "Shimeng Ye",
            "Jan Steink\u00fchler",
            "Federico Corradi"
          ],
          "year": 2025,
          "venue": "arXiv",
          "url": "https://arxiv.org/abs/2504.10053v2"
        },
        {
          "paper_id": "http://arxiv.org/abs/2104.11385v1",
          "title": "In-Situ Assessment of Device-Side Compute Work for Dynamic Load Balancing in a GPU-Accelerated PIC Code",
          "abstract": "Maintaining computational load balance is important to the performant behavior of codes which operate under a distributed computing model. This is especially true for GPU architectures, which can suffer from memory oversubscription if improperly load balanced. We present enhancements to traditional load balancing approaches and explicitly target GPU architectures, exploring the resulting performance. A key component of our enhancements is the introduction of several GPU-amenable strategies for assessing compute work. These strategies are implemented and benchmarked to find the most optimal data collection methodology for in-situ assessment of GPU compute work. For the fully kinetic particle-in-cell code WarpX, which supports MPI+CUDA parallelism, we investigate the performance of the improved dynamic load balancing via a strong scaling-based performance model and show that, for a laser-ion acceleration test problem run with up to 6144 GPUs on Summit, the enhanced dynamic load balancing achieves from 62%--74% (88% when running on 6 GPUs) of the theoretically predicted maximum speedup; for the 96-GPU case, we find that dynamic load balancing improves performance relative to baselines without load balancing (3.8x speedup) and with static load balancing (1.2x speedup). Our results provide important insights into dynamic load balancing and performance assessment, and are particularly relevant in the context of distributed memory applications ran on GPUs.",
          "authors": [
            "Michael E. Rowan",
            "Axel Huebl",
            "Kevin N. Gott",
            "Jack Deslippe",
            "Maxence Th\u00e9venet",
            "Remi Lehe",
            "Jean-Luc Vay"
          ],
          "year": 2021,
          "venue": "arXiv",
          "url": "https://arxiv.org/abs/2104.11385v1"
        },
        {
          "paper_id": "http://arxiv.org/abs/2307.11124v2",
          "title": "Approximate Computing Survey, Part I: Terminology and Software & Hardware Approximation Techniques",
          "abstract": "The rapid growth of demanding applications in domains applying multimedia processing and machine learning has marked a new era for edge and cloud computing. These applications involve massive data and compute-intensive tasks, and thus, typical computing paradigms in embedded systems and data centers are stressed to meet the worldwide demand for high performance. Concurrently, over the last 15 years, the semiconductor industry has established power efficiency as a first-class design concern. As a result, the community of computing systems is forced to find alternative design approaches to facilitate high-performance and power-efficient computing. Among the examined solutions, Approximate Computing has attracted an ever-increasing interest, which has resulted in novel approximation techniques for all the layers of the traditional computing stack. More specifically, during the last decade, a plethora of approximation techniques in software (programs, frameworks, compilers, runtimes, languages), hardware (circuits, accelerators), and architectures (processors, memories) have been proposed in the literature. The current article is Part I of a comprehensive survey on Approximate Computing. It reviews its motivation, terminology and principles, as well it classifies the state-of-the-art software & hardware approximation techniques, presents their technical details, and reports a comparative quantitative analysis.",
          "authors": [
            "Vasileios Leon",
            "Muhammad Abdullah Hanif",
            "Giorgos Armeniakos",
            "Xun Jiao",
            "Muhammad Shafique",
            "Kiamal Pekmestzi",
            "Dimitrios Soudris"
          ],
          "year": 2023,
          "venue": "arXiv",
          "url": "https://arxiv.org/abs/2307.11124v2"
        },
        {
          "paper_id": "http://arxiv.org/abs/2311.14679v2",
          "title": "\"Medium-n studies\" in computing education conferences",
          "abstract": "Good (Frequentist) statistical practice requires that statistical tests be performed in order to determine if the phenomenon being observed could plausibly occur by chance if the null hypothesis is false. Good practice also requires that a test is not performed if the study is underpowered: if the number of observations is not sufficiently large to be able to reliably detect the effect one hypothesizes, even if the effect exists. Running underpowered studies runs the risk of false negative results. This creates tension in the guidelines and expectations for computer science education conferences: while things are clear for studies with a large number of observations, researchers should in fact not compute p-values and perform statistical tests if the number of observations is too small. The issue is particularly live in CSed venues, since class sizes where those issues are salient are common. We outline the considerations for when to compute and when not to compute p-values in different settings encountered by computer science education researchers. We survey the author and reviewer guidelines in different computer science education conferences (ICER, SIGCSE TS, ITiCSE, EAAI, CompEd, Koli Calling). We present summary data and make several preliminary observations about reviewer guidelines: guidelines vary from conference to conference; guidelines allow for qualitative studies, and, in some cases, experience reports, but guidelines do not generally explicitly indicate that a paper should have at least one of (1) an appropriately-powered statistical analysis or (2) rich qualitative descriptions. We present preliminary ideas for addressing the tension in the guidelines between small-n and large-n studies",
          "authors": [
            "Michael Guerzhoy"
          ],
          "year": 2023,
          "venue": "arXiv",
          "url": "https://arxiv.org/abs/2311.14679v2"
        },
        {
          "paper_id": "http://arxiv.org/abs/2107.01984v1",
          "title": "A Systematic Literature Review of Empiricism and Norms of Reporting in Computing Education Research Literature",
          "abstract": "Computing Education Research (CER) is critical for supporting the increasing number of students who need to learn computing skills. To systematically advance knowledge, publications must be clear enough to support replications, meta-analyses, and theory-building. The goal of this study is to characterize the reporting of empiricism in CER literature by identifying whether publications include information to support replications, meta-analyses, and theory building. The research questions are: RQ1) What percentage of papers in CER venues have empirical evaluation? RQ2) What are the characteristics of the empirical evaluation? RQ3) Do the papers with empirical evaluation follow reporting norms (both for inclusion and for labeling of key information)? We conducted an SLR of 427 papers published during 2014 and 2015 in five CER venues: SIGCSE TS, ICER, ITiCSE, TOCE, and CSE. We developed and applied the CER Empiricism Assessment Rubric. Over 80% of papers had some form of empirical evaluation. Quantitative evaluation methods were the most frequent. Papers most frequently reported results on interventions around pedagogical techniques, curriculum, community, or tools. There was a split in papers that had some type of comparison between an intervention and some other data set or baseline. Many papers lacked properly reported research objectives, goals, research questions, or hypotheses, description of participants, study design, data collection, and threats to validity. CER authors are contributing empirical results to the literature; however, not all norms for reporting are met. We encourage authors to provide clear, labeled details about their work so readers can use the methodologies and results for replications and meta-analyses. As our community grows, our reporting of CER should mature to help establish computing education theory to support the next generation of computing learners.",
          "authors": [
            "Sarah Heckman",
            "Jeffrey C. Carver",
            "Mark Sherriff",
            "Ahmed Al-Zubidy"
          ],
          "year": 2021,
          "venue": "arXiv",
          "url": "https://arxiv.org/abs/2107.01984v1"
        },
        {
          "paper_id": "http://arxiv.org/abs/2307.11128v2",
          "title": "Approximate Computing Survey, Part II: Application-Specific & Architectural Approximation Techniques and Applications",
          "abstract": "The challenging deployment of compute-intensive applications from domains such as Artificial Intelligence (AI) and Digital Signal Processing (DSP), forces the community of computing systems to explore new design approaches. Approximate Computing appears as an emerging solution, allowing to tune the quality of results in the design of a system in order to improve the energy efficiency and/or performance. This radical paradigm shift has attracted interest from both academia and industry, resulting in significant research on approximation techniques and methodologies at different design layers (from system down to integrated circuits). Motivated by the wide appeal of Approximate Computing over the last 10 years, we conduct a two-part survey to cover key aspects (e.g., terminology and applications) and review the state-of-the art approximation techniques from all layers of the traditional computing stack. Part II of the survey classifies and presents the technical details of application-specific and architectural approximation techniques, which both target the design of resource-efficient processors/accelerators and systems. Moreover, it reports a quantitative analysis of the techniques and a detailed analysis of the application spectrum of Approximate Computing, and finally, it discusses open challenges and future directions.",
          "authors": [
            "Vasileios Leon",
            "Muhammad Abdullah Hanif",
            "Giorgos Armeniakos",
            "Xun Jiao",
            "Muhammad Shafique",
            "Kiamal Pekmestzi",
            "Dimitrios Soudris"
          ],
          "year": 2023,
          "venue": "arXiv",
          "url": "https://arxiv.org/abs/2307.11128v2"
        },
        {
          "paper_id": "http://arxiv.org/abs/2503.08854v2",
          "title": "Survey-Wide Asteroid Discovery with a High-Performance Computing Enabled Non-Linear Digital Tracking Framework",
          "abstract": "Modern astronomical surveys detect asteroids by linking together their appearances across multiple images taken over time. This approach faces limitations in detecting faint asteroids and handling the computational complexity of trajectory linking. We present a novel method that adapts ``digital tracking\" - traditionally used for short-term linear asteroid motion across images - to work with large-scale synoptic surveys such as the Vera Rubin Observatory Legacy Survey of Space and Time (Rubin/LSST). Our approach combines hundreds of sparse observations of individual asteroids across their non-linear orbital paths to enhance detection sensitivity by several magnitudes. To address the computational challenges of processing massive data sets and dense orbital phase spaces, we developed a specialized high-performance computing architecture. We demonstrate the effectiveness of our method through experiments that take advantage of the extensive computational resources at Lawrence Livermore National Laboratory. This work enables the detection of significantly fainter asteroids in existing and future survey data, potentially increasing the observable asteroid population by orders of magnitude across different orbital families, from near-Earth objects (NEOs) to Kuiper belt objects (KBOs).",
          "authors": [
            "Nathan Golovich",
            "Trevor Steil",
            "Alex Geringer-Sameth",
            "Keita Iwabuchi",
            "Ryan Dozier",
            "Roger Pearce"
          ],
          "year": 2025,
          "venue": "arXiv",
          "url": "https://arxiv.org/abs/2503.08854v2"
        },
        {
          "paper_id": "http://arxiv.org/abs/2511.01861v1",
          "title": "Conceptual Design Report for FAIR Computing",
          "abstract": "This Conceptual Design Report (CDR) presents the plans of the computing infrastructure for research at FAIR, Darmstadt, Germany. It presents the computing requirements of the various research groups, the policies for the computing and storage infrastructure, the foreseen FAIR computing model including the open data, software and services policies and architecture for the periods starting in 2028 with the \"first science (plus)\" phase to the modularized start version of FAIR. The overall ambition is to create a federated and centrally-orchestrated infrastructure serving the large diversity of the research lines present with sufficient scalability and flexibility to cope with future data challenges that will be present at FAIR.",
          "authors": [
            "Johan Messchendorp",
            "Mohammad Al-Turany",
            "Volker Friese",
            "Thorsten Kollegger",
            "Bastian Loeher",
            "Jochen Markert",
            "Andrew Mistry",
            "Thomas Neff",
            "Adrian Oeftiger",
            "Michael Papenbrock",
            "Stephane Pietri",
            "Shahab Sanjari",
            "Tobias Stockmanns"
          ],
          "year": 2025,
          "venue": "arXiv",
          "url": "https://arxiv.org/abs/2511.01861v1"
        },
        {
          "paper_id": "http://arxiv.org/abs/1801.04179v1",
          "title": "Arhuaco: Deep Learning and Isolation Based Security for Distributed High-Throughput Computing",
          "abstract": "Grid computing systems require innovative methods and tools to identify cybersecurity incidents and perform autonomous actions i.e. without administrator intervention. They also require methods to isolate and trace job payload activity in order to protect users and find evidence of malicious behavior. We introduce an integrated approach of security monitoring via Security by Isolation with Linux Containers and Deep Learning methods for the analysis of real time data in Grid jobs running inside virtualized High-Throughput Computing infrastructure in order to detect and prevent intrusions. A dataset for malware detection in Grid computing is described. We show in addition the utilization of generative methods with Recurrent Neural Networks to improve the collected dataset. We present Arhuaco, a prototype implementation of the proposed methods. We empirically study the performance of our technique. The results show that Arhuaco outperforms other methods used in Intrusion Detection Systems for Grid Computing. The study is carried out in the ALICE Collaboration Grid, part of the Worldwide LHC Computing Grid.",
          "authors": [
            "A. Gomez Ramirez",
            "C. Lara",
            "L. Betev",
            "D. Bilanovic",
            "U. Kebschull"
          ],
          "year": 2018,
          "venue": "arXiv",
          "url": "https://arxiv.org/abs/1801.04179v1"
        },
        {
          "paper_id": "http://arxiv.org/abs/1808.02838v1",
          "title": "On the Effect of Task-to-Worker Assignment in Distributed Computing Systems with Stragglers",
          "abstract": "We study the expected completion time of some recently proposed algorithms for distributed computing which redundantly assign computing tasks to multiple machines in order to tolerate a certain number of machine failures. We analytically show that not only the amount of redundancy but also the task-to-machine assignments affect the latency in a distributed system. We study systems with a fixed number of computing tasks that are split in possibly overlapping batches, and independent exponentially distributed machine service times. We show that, for such systems, the uniform replication of non- overlapping (disjoint) batches of computing tasks achieves the minimum expected computing time.",
          "authors": [
            "Amir Behrouzi-Far",
            "Emina Soljanin"
          ],
          "year": 2018,
          "venue": "arXiv",
          "url": "https://arxiv.org/abs/1808.02838v1"
        },
        {
          "paper_id": "http://arxiv.org/abs/1504.00806v1",
          "title": "Synergy of Volunteer Measurements and Volunteer Computing for Effective Data Collecting, Processing, Simulating and Analyzing on a Worldwide Scale",
          "abstract": "The paper concerns the hype idea of \"Citizen Science\" and the related paradigm shift: to go from the passive \"volunteer computing\" to other volunteer actions like \"volunteer measurements\" under guidance of scientists. They can be carried out by ordinary people with standard computing gadgets (smartphone, tablet, etc.) and the various standard sensors in them. Here the special attention is paid to the system of volunteer scientific measurements to study air showers caused by cosmic rays. The technical implementation is based on integration of data about registered night flashes (by radiometric software) in shielded camera chip, synchronized time and GPS-data in ordinary gadgets: to identify night \"air showers\" of elementary particles; to analyze the frequency and to map the distribution of \"air showers\" in the densely populated cities. The project currently includes the students of the National Technical University of Ukraine \"KPI\", which are compactly located in Kyiv city and contribute their volunteer measurements. The technology would be very effective for other applications also, especially if it will be automated (e.g., on the basis of XtremWeb or/and BOINC technologies for distributed computing) and used in some small area with many volunteers, e.g. in local communities (Corporative/Community Crowd Computing).",
          "authors": [
            "Nikita Gordienko",
            "Oleg Lodygensky",
            "Gilles Fedak",
            "Yuri Gordienko"
          ],
          "year": 2015,
          "venue": "arXiv",
          "url": "https://arxiv.org/abs/1504.00806v1"
        }
      ],
      "key_papers": [
        "Survey-Wide Asteroid Discovery with a High-Performance Computing Enabled Non-Linear Digital Tracking Framework (Golovich et al., 2025)",
        "Synthetic Biology meets Neuromorphic Computing: Towards a bio-inspired Olfactory Perception System (Max et al., 2025)",
        "Conceptual Design Report for FAIR Computing (Messchendorp et al., 2025)"
      ],
      "avg_year": 2021.5454545454545,
      "year_distribution": {
        "2025": 3,
        "2021": 2,
        "2023": 3,
        "2018": 2,
        "2015": 1
      }
    },
    {
      "cluster_id": "2",
      "name": "Edge Computing",
      "paper_count": 9,
      "trajectory": "Declining",
      "papers": [
        {
          "paper_id": "http://arxiv.org/abs/2207.05399v2",
          "title": "Placement of Microservices-based IoT Applications in Fog Computing: A Taxonomy and Future Directions",
          "abstract": "The Fog computing paradigm utilises distributed, heterogeneous and resource-constrained devices at the edge of the network for efficient deployment of latency-critical and bandwidth-hungry IoT application services. Moreover, MicroService Architecture (MSA) is increasingly adopted to keep up with the rapid development and deployment needs of fast-evolving IoT applications. Due to the fine-grained modularity of the microservices and their independently deployable and scalable nature, MSA exhibits great potential in harnessing Fog and Cloud resources, thus giving rise to novel paradigms like Osmotic computing. The loosely coupled nature of the microservices, aided by the container orchestrators and service mesh technologies, enables the dynamic composition of distributed and scalable microservices to achieve diverse performance requirements of the IoT applications using distributed Fog resources. To this end, efficient placement of microservice plays a vital role, and scalable placement algorithms are required to utilise the said characteristics of the MSA while overcoming novel challenges introduced by the architecture. Thus, we present a comprehensive taxonomy of recent literature on microservices-based IoT applications placement within Fog computing environments. Furthermore, we organise multiple taxonomies to capture the main aspects of the placement problem, analyse and classify related works, identify research gaps within each category, and discuss future research directions.",
          "authors": [
            "Samodha Pallewatta",
            "Vassilis Kostakos",
            "Rajkumar Buyya"
          ],
          "year": 2022,
          "venue": "arXiv",
          "url": "https://arxiv.org/abs/2207.05399v2"
        },
        {
          "paper_id": "http://arxiv.org/abs/2109.12195v1",
          "title": "A Manifesto for Modern Fog and Edge Computing: Vision, New Paradigms, Opportunities, and Future Directions",
          "abstract": "The advancements in the use of Internet of Things (IoT) devices is increasing continuously and generating huge amounts of data in a fast manner. Cloud computing is an important paradigm which processes and manages user data effectively. Further, fog and edge computing paradigms are introduced to improve user service by reducing latency and response time. This chapter presents a manifesto for modern fog and edge computing systems based on the current research trends. Further, architectures and applications of fog and edge computing are explained. Moreover, research opportunities and promising future directions are presented with respect to the new paradigms, which will be helpful for practitioners, researchers, and academicians to continue their research.",
          "authors": [
            "Sukhpal Singh Gill"
          ],
          "year": 2021,
          "venue": "arXiv",
          "url": "https://arxiv.org/abs/2109.12195v1"
        },
        {
          "paper_id": "http://arxiv.org/abs/2504.03671v1",
          "title": "HiAER-Spike: Hardware-Software Co-Design for Large-Scale Reconfigurable Event-Driven Neuromorphic Computing",
          "abstract": "In this work, we present HiAER-Spike, a modular, reconfigurable, event-driven neuromorphic computing platform designed to execute large spiking neural networks with up to 160 million neurons and 40 billion synapses - roughly twice the neurons of a mouse brain at faster-than real-time. This system, which is currently under construction at the UC San Diego Supercomputing Center, comprises a co-designed hard- and software stack that is optimized for run-time massively parallel processing and hierarchical address-event routing (HiAER) of spikes while promoting memory-efficient network storage and execution. Our architecture efficiently handles both sparse connectivity and sparse activity for robust and low-latency event-driven inference for both edge and cloud computing. A Python programming interface to HiAER-Spike, agnostic to hardware-level detail, shields the user from complexity in the configuration and execution of general spiking neural networks with virtually no constraints in topology. The system is made easily available over a web portal for use by the wider community. In the following we provide an overview of the hard- and software stack, explain the underlying design principles, demonstrate some of the system's capabilities and solicit feedback from the broader neuromorphic community.",
          "authors": [
            "Gwenevere Frank",
            "Gopabandhu Hota",
            "Keli Wang",
            "Abhinav Uppal",
            "Omowuyi Olajide",
            "Kenneth Yoshimoto",
            "Leif Gibb",
            "Qingbo Wang",
            "Johannes Leugering",
            "Stephen Deiss",
            "Gert Cauwenberghs"
          ],
          "year": 2025,
          "venue": "arXiv",
          "url": "https://arxiv.org/abs/2504.03671v1"
        },
        {
          "paper_id": "http://arxiv.org/abs/1801.05610v3",
          "title": "A Taxonomy for Management and Optimization of Multiple Resources in Edge Computing",
          "abstract": "Edge computing is promoted to meet increasing performance needs of data-driven services using computational and storage resources close to the end devices, at the edge of the current network. To achieve higher performance in this new paradigm one has to consider how to combine the efficiency of resource usage at all three layers of architecture: end devices, edge devices, and the cloud. While cloud capacity is elastically extendable, end devices and edge devices are to various degrees resource-constrained. Hence, an efficient resource management is essential to make edge computing a reality. In this work, we first present terminology and architectures to characterize current works within the field of edge computing. Then, we review a wide range of recent articles and categorize relevant aspects in terms of 4 perspectives: resource type, resource management objective, resource location, and resource use. This taxonomy and the ensuing analysis is used to identify some gaps in the existing research. Among several research gaps, we found that research is less prevalent on data, storage, and energy as a resource, and less extensive towards the estimation, discovery and sharing objectives. As for resource types, the most well-studied resources are computation and communication resources. Our analysis shows that resource management at the edge requires a deeper understanding of how methods applied at different levels and geared towards different resource types interact. Specifically, the impact of mobility and collaboration schemes requiring incentives are expected to be different in edge architectures compared to the classic cloud solutions. Finally, we find that fewer works are dedicated to the study of non-functional properties or to quantifying the footprint of resource management techniques, including edge-specific means of migrating data and services.",
          "authors": [
            "Klervie Tocz\u00e9",
            "Simin Nadjm-Tehrani"
          ],
          "year": 2018,
          "venue": "arXiv",
          "url": "https://arxiv.org/abs/1801.05610v3"
        },
        {
          "paper_id": "http://arxiv.org/abs/1810.06046v1",
          "title": "Accelerator Virtualization in Fog Computing: Moving From the Cloud to the Edge",
          "abstract": "Hardware accelerators are available on the Cloud for enhanced analytics. Next generation Clouds aim to bring enhanced analytics using accelerators closer to user devices at the edge of the network for improving Quality-of-Service by minimizing end-to-end latencies and response times. The collective computing model that utilizes resources at the Cloud-Edge continuum in a multi-tier hierarchy comprising the Cloud, the Edge and user devices is referred to as Fog computing. This article identifies challenges and opportunities in making accelerators accessible at the Edge. A holistic view of the Fog architecture is key to pursuing meaningful research in this area.",
          "authors": [
            "Blesson Varghese",
            "Carlos Reano",
            "Federico Silla"
          ],
          "year": 2018,
          "venue": "arXiv",
          "url": "https://arxiv.org/abs/1810.06046v1"
        },
        {
          "paper_id": "http://arxiv.org/abs/1711.03660v1",
          "title": "TARCO: Two-Stage Auction for D2D Relay Aided Computation Resource Allocation in Hetnet",
          "abstract": "In heterogeneous cellular network, task scheduling for computation offloading is one of the biggest challenges. Most works focus on alleviating heavy burden of macro base stations by moving the computation tasks on macro-cell user equipment (MUE) to remote cloud or small-cell base stations. But the selfishness of network users is seldom considered. Motivated by the cloud edge computing, this paper provides incentive for task transfer from macro cell users to small cell base stations. The proposed incentive scheme utilizes small cell user equipment to provide relay service. The problem of computation offloading is modelled as a two-stage auction, in which the remote MUEs with common social character can form a group and then buy the computation resource of small-cell base stations with the relay of small cell user equipment. A two-stage auction scheme named TARCO is contributed to maximize utilities for both sellers and buyers in the network. The truthful, individual rationality and budget balance of the TARCO are also proved in this paper. In addition, two algorithms are proposed to further refine TARCO on the social welfare of the network. Extensive simulation results demonstrate that, TARCO is better than random algorithm by about 104.90% in terms of average utility of MUEs, while the performance of TARCO is further improved up to 28.75% and 17.06% by the proposed two algorithms, respectively.",
          "authors": [
            "Long Chen",
            "Jigang Wu",
            "Xinxiang Zhang"
          ],
          "year": 2017,
          "venue": "arXiv",
          "url": "https://arxiv.org/abs/1711.03660v1"
        },
        {
          "paper_id": "http://arxiv.org/abs/1705.08449v4",
          "title": "Developing an edge computing platform for real-time descriptive analytics",
          "abstract": "The Internet of Mobile Things encompasses stream data being generated by sensors, network communications that pull and push these data streams, as well as running processing and analytics that can effectively leverage actionable information for transportation planning, management, and business advantage. Edge computing emerges as a new paradigm that decentralizes the communication, computation, control and storage resources from the cloud to the edge of the network. This paper proposes an edge computing platform where mobile edge nodes are physical devices deployed on a transit bus where descriptive analytics is used to uncover meaningful patterns from real-time transit data streams. An application experiment is used to evaluate the advantages and disadvantages of our proposed platform to support descriptive analytics at a mobile edge node and generate actionable information to transit managers.",
          "authors": [
            "Hung Cao",
            "Monica Wachowicz",
            "Sangwhan Cha"
          ],
          "year": 2017,
          "venue": "arXiv",
          "url": "https://arxiv.org/abs/1705.08449v4"
        },
        {
          "paper_id": "http://arxiv.org/abs/2103.04505v4",
          "title": "Split Computing and Early Exiting for Deep Learning Applications: Survey and Research Challenges",
          "abstract": "Mobile devices such as smartphones and autonomous vehicles increasingly rely on deep neural networks (DNNs) to execute complex inference tasks such as image classification and speech recognition, among others. However, continuously executing the entire DNN on mobile devices can quickly deplete their battery. Although task offloading to cloud/edge servers may decrease the mobile device's computational burden, erratic patterns in channel quality, network, and edge server load can lead to a significant delay in task execution. Recently, approaches based on split computing (SC) have been proposed, where the DNN is split into a head and a tail model, executed respectively on the mobile device and on the edge server. Ultimately, this may reduce bandwidth usage as well as energy consumption. Another approach, called early exiting (EE), trains models to embed multiple \"exits\" earlier in the architecture, each providing increasingly higher target accuracy. Therefore, the trade-off between accuracy and delay can be tuned according to the current conditions or application demands. In this paper, we provide a comprehensive survey of the state of the art in SC and EE strategies by presenting a comparison of the most relevant approaches. We conclude the paper by providing a set of compelling research challenges.",
          "authors": [
            "Yoshitomo Matsubara",
            "Marco Levorato",
            "Francesco Restuccia"
          ],
          "year": 2021,
          "venue": "arXiv",
          "url": "https://arxiv.org/abs/2103.04505v4"
        },
        {
          "paper_id": "http://arxiv.org/abs/1702.06082v1",
          "title": "Coding for Distributed Fog Computing",
          "abstract": "Redundancy is abundant in Fog networks (i.e., many computing and storage points) and grows linearly with network size. We demonstrate the transformational role of coding in Fog computing for leveraging such redundancy to substantially reduce the bandwidth consumption and latency of computing. In particular, we discuss two recently proposed coding concepts, namely Minimum Bandwidth Codes and Minimum Latency Codes, and illustrate their impacts in Fog computing. We also review a unified coding framework that includes the above two coding techniques as special cases, and enables a tradeoff between computation latency and communication load to optimize system performance. At the end, we will discuss several open problems and future research directions.",
          "authors": [
            "Songze Li",
            "Mohammad Ali Maddah-Ali",
            "A. Salman Avestimehr"
          ],
          "year": 2017,
          "venue": "arXiv",
          "url": "https://arxiv.org/abs/1702.06082v1"
        }
      ],
      "key_papers": [
        "HiAER-Spike: Hardware-Software Co-Design for Large-Scale Reconfigurable Event-Driven Neuromorphic Computing (Frank et al., 2025)",
        "Placement of Microservices-based IoT Applications in Fog Computing: A Taxonomy and Future Directions (Pallewatta et al., 2022)",
        "A Manifesto for Modern Fog and Edge Computing: Vision, New Paradigms, Opportunities, and Future Directions (Gill et al., 2021)"
      ],
      "avg_year": 2019.5555555555557,
      "year_distribution": {
        "2022": 1,
        "2021": 2,
        "2025": 1,
        "2018": 2,
        "2017": 3
      }
    },
    {
      "cluster_id": "1",
      "name": "Quantum Computing",
      "paper_count": 5,
      "trajectory": "Stable",
      "papers": [
        {
          "paper_id": "http://arxiv.org/abs/2211.02350v1",
          "title": "Tierkreis: A Dataflow Framework for Hybrid Quantum-Classical Computing",
          "abstract": "We present Tierkreis, a higher-order dataflow graph program representation and runtime designed for compositional, quantum-classical hybrid algorithms. The design of the system is motivated by the remote nature of quantum computers, the need for hybrid algorithms to involve cloud and distributed computing, and the long-running nature of these algorithms. The graph-based representation reflects how designers reason about and visualise algorithms, and allows automatic parallelism and asynchronicity. A strong, static type system and higher-order semantics allow for high expressivity and compositionality in the program. The flexible runtime protocol enables third-party developers to add functionality using any language or environment. With Tierkreis, quantum software developers can easily build, visualise, verify, test, and debug complex hybrid workflows, and immediately deploy them to the cloud or a custom distributed environment.",
          "authors": [
            "Seyon Sivarajah",
            "Lukas Heidemann",
            "Alan Lawrence",
            "Ross Duncan"
          ],
          "year": 2022,
          "venue": "arXiv",
          "url": "https://arxiv.org/abs/2211.02350v1"
        },
        {
          "paper_id": "http://arxiv.org/abs/2403.02240v5",
          "title": "Quantum Computing: Vision and Challenges",
          "abstract": "The recent development of quantum computing, which uses entanglement, superposition, and other quantum fundamental concepts, can provide substantial processing advantages over traditional computing. These quantum features help solve many complex problems that cannot be solved otherwise with conventional computing methods. These problems include modeling quantum mechanics, logistics, chemical-based advances, drug design, statistical science, sustainable energy, banking, reliable communication, and quantum chemical engineering. The last few years have witnessed remarkable progress in quantum software and algorithm creation and quantum hardware research, which has significantly advanced the prospect of realizing quantum computers. It would be helpful to have comprehensive literature research on this area to grasp the current status and find outstanding problems that require considerable attention from the research community working in the quantum computing industry. To better understand quantum computing, this paper examines the foundations and vision based on current research in this area. We discuss cutting-edge developments in quantum computer hardware advancement and subsequent advances in quantum cryptography, quantum software, and high-scalability quantum computers. Many potential challenges and exciting new trends for quantum technology research and development are highlighted in this paper for a broader debate.",
          "authors": [
            "Sukhpal Singh Gill",
            "Oktay Cetinkaya",
            "Stefano Marrone",
            "Daniel Claudino",
            "David Haunschild",
            "Leon Schlote",
            "Huaming Wu",
            "Carlo Ottaviani",
            "Xiaoyuan Liu",
            "Sree Pragna Machupalli",
            "Kamalpreet Kaur",
            "Priyansh Arora",
            "Ji Liu",
            "Ahmed Farouk",
            "Houbing Herbert Song",
            "Steve Uhlig",
            "Kotagiri Ramamohanarao"
          ],
          "year": 2024,
          "venue": "arXiv",
          "url": "https://arxiv.org/abs/2403.02240v5"
        },
        {
          "paper_id": "http://arxiv.org/abs/2011.10569v1",
          "title": "Vector computation",
          "abstract": "Quantum physical resources are directional quantities that can be formalized by unit vectors or the associated orthogonal projection operators. When compared to classical computational states which are elements of (power) sets vector computations offer (dis)advantages.",
          "authors": [
            "Karl Svozil"
          ],
          "year": 2020,
          "venue": "arXiv",
          "url": "https://arxiv.org/abs/2011.10569v1"
        },
        {
          "paper_id": "http://arxiv.org/abs/1509.09180v4",
          "title": "How to Verify a Quantum Computation",
          "abstract": "We give a new theoretical solution to a leading-edge experimental challenge, namely to the verification of quantum computations in the regime of high computational complexity. Our results are given in the language of quantum interactive proof systems. Specifically, we show that any language in $\\mathsf{BQP}$ has a quantum interactive proof system with a polynomial-time classical verifier (who can also prepare random single-qubit pure states), and a quantum polynomial-time prover. Here, soundness is unconditional--i.e., it holds even for computationally unbounded provers. Compared to prior work achieving similar results, our technique does not require the encoding of the input or of the computation; instead, we rely on encryption of the input (together with a method to perform computations on encrypted inputs), and show that the random choice between three types of input (defining a computational run, versus two types of test runs) suffices. Because the overhead is very low for each run (it is linear in the size of the circuit), this shows that verification could be achieved at minimal cost compared to performing the computation. As a proof technique, we use a reduction to an entanglement-based protocol; to the best of our knowledge, this is the first time this technique has been used in the context of verification of quantum computations, and it enables a relatively straightforward analysis.",
          "authors": [
            "Anne Broadbent"
          ],
          "year": 2015,
          "venue": "arXiv",
          "url": "https://arxiv.org/abs/1509.09180v4"
        },
        {
          "paper_id": "http://arxiv.org/abs/2112.00984v1",
          "title": "Measurement Crosstalk Errors in Cloud-Based Quantum Computing",
          "abstract": "Quantum technologies available currently contain noise in general, often dubbed noisy intermediate-scale quantum (NISQ) systems. We here present the verification of noise in measurement readout errors in cloud-based quantum computing services, IBMQ and Rigetti, by directly performing quantum detector tomography, and show that there exist measurement crosstalk errors. We provide the characterization and the quantification of noise in a quantum measurement of multiple qubits. We remark that entanglement is found as a source of crosstalk errors in a measurement of three qubits.",
          "authors": [
            "Seungchan Seo",
            "Joonwoo Bae"
          ],
          "year": 2021,
          "venue": "arXiv",
          "url": "https://arxiv.org/abs/2112.00984v1"
        }
      ],
      "key_papers": [
        "Quantum Computing: Vision and Challenges (Gill et al., 2024)",
        "Tierkreis: A Dataflow Framework for Hybrid Quantum-Classical Computing (Sivarajah et al., 2022)",
        "Measurement Crosstalk Errors in Cloud-Based Quantum Computing (Seo et al., 2021)"
      ],
      "avg_year": 2020.4,
      "year_distribution": {
        "2022": 1,
        "2024": 1,
        "2020": 1,
        "2015": 1,
        "2021": 1
      }
    },
    {
      "cluster_id": "3",
      "name": "Serverless Cold",
      "paper_count": 4,
      "trajectory": "Rising",
      "papers": [
        {
          "paper_id": "http://arxiv.org/abs/2310.08437v2",
          "title": "Cold Start Latency in Serverless Computing: A Systematic Review, Taxonomy, and Future Directions",
          "abstract": "Recently, academics and the corporate sector have paid attention to serverless computing, which enables dynamic scalability and an economic model. In serverless computing, users only pay for the time they actually use resources, enabling zero scaling to optimise cost and resource utilisation. However, this approach also introduces the serverless cold start problem. Researchers have developed various solutions to address the cold start problem, yet it remains an unresolved research area. In this article, we propose a systematic literature review on clod start latency in serverless computing. Furthermore, we create a detailed taxonomy of approaches to cold start latency, which we use to investigate existing techniques for reducing the cold start time and frequency. We have classified the current studies on cold start latency into several categories such as caching and application-level optimisation-based solutions, as well as Artificial Intelligence (AI)/Machine Learning (ML)-based solutions. Moreover, we have analyzed the impact of cold start latency on quality of service, explored current cold start latency mitigation methods, datasets, and implementation platforms, and classified them into categories based on their common characteristics and features. Finally, we outline the open challenges and highlight the possible future directions.",
          "authors": [
            "Muhammed Golec",
            "Guneet Kaur Walia",
            "Mohit Kumar",
            "Felix Cuadrado",
            "Sukhpal Singh Gill",
            "Steve Uhlig"
          ],
          "year": 2023,
          "venue": "arXiv",
          "url": "https://arxiv.org/abs/2310.08437v2"
        },
        {
          "paper_id": "http://arxiv.org/abs/2505.19880v2",
          "title": "Universal Workers: A Vision for Eliminating Cold Starts in Serverless Computing",
          "abstract": "Serverless computing enables developers to deploy code without managing infrastructure, but suffers from cold start overhead when initializing new function instances. Existing solutions such as \"keep-alive\" or \"pre-warming\" are costly and unreliable under bursty workloads. We propose universal workers, which are computational units capable of executing any function with minimal initialization overhead. Based on an analysis of production workload traces, our key insight is that requests in Function-as-a-Service (FaaS) platforms show a highly skewed distribution, with most requests invoking a small subset of functions. We exploit this observation to approximate universal workers through locality groups and three-tier caching (handler, install, import). With this work, we aim to enable more efficient and scalable FaaS platforms capable of handling diverse workloads with minimal initialization overhead.",
          "authors": [
            "Saman Akbari",
            "Manfred Hauswirth"
          ],
          "year": 2025,
          "venue": "arXiv",
          "url": "https://arxiv.org/abs/2505.19880v2"
        },
        {
          "paper_id": "http://arxiv.org/abs/2209.09367v4",
          "title": "Supporting Multi-Cloud in Serverless Computing",
          "abstract": "Serverless computing is a widely adopted cloud execution model composed of Function-as-a-Service (FaaS) and Backend-as-a-Service (BaaS) offerings. The increased level of abstraction makes vendor lock-in inherent to serverless computing, raising more concerns than previous cloud paradigms. Multi-cloud serverless is a promising emerging approach against vendor lock-in, yet multiple challenges must be overcome to tap its potential. First, we need to be aware of both the performance and cost of each FaaS provider. Second, a multi-cloud architecture must be proposed before deploying a multi-cloud workflow. Domain-specific serverless offerings must then be integrated into the multi-cloud architecture to improve performance or save costs. Moreover, dealing with serverless offerings from multiple providers is challenging. Finally, we require workload portability support for serverless multi-cloud.   In this paper, we present a multi-cloud library for cross-serverless offerings. We develop the End Analysis System (EAS) to support comparison among public FaaS providers in terms of performance and cost. Moreover, we design proof-of-concept multi-cloud architectures with domain-specific serverless offerings to alleviate problems such as data gravity. Finally, we deploy workloads on these architectures to evaluate several public FaaS offerings.",
          "authors": [
            "Haidong Zhao",
            "Zakaria Benomar",
            "Tobias Pfandzelter",
            "Nikolaos Georgantas"
          ],
          "year": 2022,
          "venue": "arXiv",
          "url": "https://arxiv.org/abs/2209.09367v4"
        },
        {
          "paper_id": "http://arxiv.org/abs/2106.09922v1",
          "title": "A Fresh Approach to Evaluate Performance in Distributed Parallel Genetic Algorithms",
          "abstract": "This work proposes a novel approach to evaluate and analyze the behavior of multi-population parallel genetic algorithms (PGAs) when running on a cluster of multi-core processors. In particular, we deeply study their numerical and computational behavior by proposing a mathematical model representing the observed performance curves. In them, we discuss the emerging mathematical descriptions of PGA performance instead of, e.g., individual isolated results subject to visual inspection, for a better understanding of the effects of the number of cores used (scalability), their migration policy (the migration gap, in this paper), and the features of the solved problem (type of encoding and problem size). The conclusions based on the real figures and the numerical models fitting them represent a fresh way of understanding their speed-up, running time, and numerical effort, allowing a comparison based on a few meaningful numeric parameters. This represents a set of conclusions beyond the usual textual lessons found in past works on PGAs. It can be used as an estimation tool for the future performance of the algorithms and a way of finding out their limitations.",
          "authors": [
            "Tomohiro Harada",
            "Enrique Alba",
            "Gabriel Luque"
          ],
          "year": 2021,
          "venue": "arXiv",
          "url": "https://arxiv.org/abs/2106.09922v1"
        }
      ],
      "key_papers": [
        "Universal Workers: A Vision for Eliminating Cold Starts in Serverless Computing (Akbari et al., 2025)",
        "Cold Start Latency in Serverless Computing: A Systematic Review, Taxonomy, and Future Directions (Golec et al., 2023)",
        "Supporting Multi-Cloud in Serverless Computing (Zhao et al., 2022)"
      ],
      "avg_year": 2022.75,
      "year_distribution": {
        "2023": 1,
        "2025": 1,
        "2022": 1,
        "2021": 1
      }
    },
    {
      "cluster_id": "4",
      "name": "Computing Cloud",
      "paper_count": 3,
      "trajectory": "Stable",
      "papers": [
        {
          "paper_id": "http://arxiv.org/abs/2010.08774v1",
          "title": "The role of interactive super-computing in using HPC for urgent decision making",
          "abstract": "Technological advances are creating exciting new opportunities that have the potential to move HPC well beyond traditional computational workloads. In this paper we focus on the potential for HPC to be instrumental in responding to disasters such as wildfires, hurricanes, extreme flooding, earthquakes, tsunamis, winter weather conditions, and accidents. Driven by the VESTEC EU funded H2020 project, our research looks to prove HPC as a tool not only capable of simulating disasters once they have happened, but also one which is able to operate in a responsive mode, supporting disaster response teams making urgent decisions in real-time. Whilst this has the potential to revolutionise disaster response, it requires the ability to drive HPC interactively, both from the user's perspective and also based upon the arrival of data. As such interactivity is a critical component in enabling HPC to be exploited in the role of supporting disaster response teams so that urgent decision makers can make the correct decision first time, every time.",
          "authors": [
            "Nick Brown",
            "Rupert Nash",
            "Gordon Gibb",
            "Bianca Prodan",
            "Max Kontak",
            "Vyacheslav Olshevsky",
            "Wei Der Chien"
          ],
          "year": 2020,
          "venue": "arXiv",
          "url": "https://arxiv.org/abs/2010.08774v1"
        },
        {
          "paper_id": "http://arxiv.org/abs/2212.02378v1",
          "title": "Confidential High-Performance Computing in the Public Cloud",
          "abstract": "High-Performance Computing (HPC) in the public cloud democratizes the supercomputing power that most users cannot afford to purchase and maintain. Researchers have studied its viability, performance, and usability. However, HPC in the cloud has a unique feature -- users have to export data and computation to somewhat untrusted cloud platforms. Users will either fully trust cloud providers to protect from all kinds of attacks or keep sensitive assets in-house instead. With the recent deployment of the Trusted Execution Environment (TEE) in the cloud, confidential computing for HPC in the cloud is becoming practical for addressing users' privacy concerns. This paper discusses the threat models, unique challenges, possible solutions, and significant gaps, focusing on TEE-based confidential HPC computing. We hope this discussion will improve the understanding of this new topic for HPC in the cloud and promote new research directions.",
          "authors": [
            "Keke Chen"
          ],
          "year": 2022,
          "venue": "arXiv",
          "url": "https://arxiv.org/abs/2212.02378v1"
        },
        {
          "paper_id": "http://arxiv.org/abs/2204.12580v1",
          "title": "Scheduling IoT Applications in Edge and Fog Computing Environments: A Taxonomy and Future Directions",
          "abstract": "Fog computing, as a distributed paradigm, offers cloud-like services at the edge of the network with low latency and high-access bandwidth to support a diverse range of IoT application scenarios. To fully utilize the potential of this computing paradigm, scalable, adaptive, and accurate scheduling mechanisms and algorithms are required to efficiently capture the dynamics and requirements of users, IoT applications, environmental properties, and optimization targets. This paper presents a taxonomy of recent literature on scheduling IoT applications in Fog computing. Based on our new classification schemes, current works in the literature are analyzed, research gaps of each category are identified, and respective future directions are described.",
          "authors": [
            "Mohammad Goudarzi",
            "Marimuthu Palaniswami",
            "Rajkumar Buyya"
          ],
          "year": 2022,
          "venue": "arXiv",
          "url": "https://arxiv.org/abs/2204.12580v1"
        }
      ],
      "key_papers": [
        "Scheduling IoT Applications in Edge and Fog Computing Environments: A Taxonomy and Future Directions (Goudarzi et al., 2022)",
        "Confidential High-Performance Computing in the Public Cloud (Chen et al., 2022)",
        "The role of interactive super-computing in using HPC for urgent decision making (Brown et al., 2020)"
      ],
      "avg_year": 2021.3333333333333,
      "year_distribution": {
        "2020": 1,
        "2022": 2
      }
    },
    {
      "cluster_id": "5",
      "name": "Moid Algorithm",
      "paper_count": 2,
      "trajectory": "Declining",
      "papers": [
        {
          "paper_id": "http://arxiv.org/abs/2011.12148v1",
          "title": "Fast error-safe MOID computation involving hyperbolic orbits",
          "abstract": "We extend our previous algorithm computing the minimum orbital intersection distance (MOID) to include hyperbolic orbits, and mixed combinations ellipse--hyperbola. The MOID is computed by finding all stationary points of the distance function, equivalent to finding all the roots of an algebraic polynomial equation of 16th degree. The updated algorithm carries about numerical errors as well, and benchmarks confirmed its numeric reliability together with high computing performance.",
          "authors": [
            "Roman. V. Baluev"
          ],
          "year": 2020,
          "venue": "arXiv",
          "url": "https://arxiv.org/abs/2011.12148v1"
        },
        {
          "paper_id": "http://arxiv.org/abs/1811.06373v2",
          "title": "Fast error-controlling MOID computation for confocal elliptic orbits",
          "abstract": "We present an algorithm to compute the minimum orbital intersection distance (MOID), or global minimum of the distance between the points lying on two Keplerian ellipses. This is achieved by finding all stationary points of the distance function, based on solving an algebraic polynomial equation of $16$th degree. The algorithm tracks numerical errors appearing on the way, and treats carefully nearly degenerate cases, including practical cases with almost circular and almost coplanar orbits. Benchmarks confirm its high numeric reliability and accuracy, and that regardless of its error--controlling overheads, this algorithm pretends to be one of the fastest MOID computation methods available to date, so it may be useful in processing large catalogs.",
          "authors": [
            "Roman V. Baluev",
            "Denis V. Mikryukov"
          ],
          "year": 2018,
          "venue": "arXiv",
          "url": "https://arxiv.org/abs/1811.06373v2"
        }
      ],
      "key_papers": [
        "Fast error-safe MOID computation involving hyperbolic orbits (Baluev et al., 2020)",
        "Fast error-controlling MOID computation for confocal elliptic orbits (Baluev et al., 2018)"
      ],
      "avg_year": 2019.0,
      "year_distribution": {
        "2020": 1,
        "2018": 1
      }
    }
  ]
}